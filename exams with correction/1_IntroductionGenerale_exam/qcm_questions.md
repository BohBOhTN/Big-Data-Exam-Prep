# QCM - Introduction au Big Data

## Chapitre 1 : Introduction Générale au Big Data

**Auteur du cours:** Mohamed KOUBAA  
**Nombre de questions:** 40

---

### Question 1
Selon le concept du Big Data, à quelle fréquence les données mondiales doublent-elles ?

- A) Tous les 6 mois
- B) Tous les ans
- C) Tous les 2 ans
- D) Tous les 5 ans

---

### Question 2
Quel pourcentage des données mondiales est considéré comme non structuré ?

- A) 50%
- B) 70%
- C) 80%
- D) 90%

---

### Question 3
Quels sont les 3V originaux du Big Data ?

- A) Volume, Vitesse, Visualisation
- B) Volume, Vélocité, Variété
- C) Valeur, Véracité, Volume
- D) Variété, Valeur, Vitesse

---

### Question 4
Que représente la "Véracité" dans le modèle des 5V du Big Data ?

- A) La vitesse de traitement des données
- B) La quantité de données
- C) La fiabilité et la crédibilité des données collectées
- D) Le format des données

---

### Question 5
Combien de tweets sont publiés par seconde sur Twitter (approximativement) ?

- A) 1,000 tweets/seconde
- B) 3,500 tweets/seconde
- C) 5,900 tweets/seconde
- D) 10,000 tweets/seconde

---

### Question 6
Quelle est l'unité de stockage équivalente à 1,024 Téraoctets ?

- A) Gigaoctet
- B) Exaoctet
- C) Pétaoctet
- D) Zettaoctet

---

### Question 7
En quelle année Google a-t-il publié le papier sur MapReduce ?

- A) 2001
- B) 2003
- C) 2004
- D) 2006

---

### Question 8
Quel framework est utilisé pour le traitement distribué en temps réel (stream processing) ?

- A) MapReduce
- B) Apache Sqoop
- C) Apache Storm
- D) Apache Pig

---

### Question 9
Quelle technologie est décrite comme un système de fichiers distribués ?

- A) Apache Hive
- B) HDFS (Hadoop Distributed File System)
- C) MongoDB
- D) Apache Kafka

---

### Question 10
Quel est le rôle principal d'Apache Sqoop ?

- A) Traitement de flux en temps réel
- B) Transfert de données entre bases relationnelles et Hadoop
- C) Stockage de données NoSQL
- D) Orchestration de workflows

---

### Question 11
Le traitement par lots (Batch Processing) se caractérise par :

- A) Le traitement des données en temps réel et continu
- B) Le traitement de blocs de données déjà stockées sur une période définie
- C) Le traitement instantané de chaque enregistrement dès son arrivée
- D) Le traitement uniquement des données structurées

---

### Question 12
Quelle base de données NoSQL stocke les données sous forme de documents JSON distribués ?

- A) Apache HBase
- B) Cassandra
- C) MongoDB
- D) ElasticSearch

---

### Question 13
Qu'est-ce que le "Micro-batch Processing" ?

- A) Traitement d'un seul enregistrement à la fois
- B) Regroupement des enregistrements toutes les quelques secondes puis traitement en mini-lot
- C) Traitement uniquement des petits fichiers
- D) Compression des données avant traitement

---

### Question 14
Quelle quantité de données représente environ 6 millions de livres ?

- A) 1 Gigaoctet
- B) 1 Téraoctet
- C) 1 Pétaoctet
- D) 1 Exaoctet

---

### Question 15
Apache Hive est principalement utilisé pour :

- A) Le traitement de flux en temps réel
- B) L'infrastructure d'entrepôt de données avec langage SQL-like
- C) La messagerie entre applications
- D) Le machine learning

---

### Question 16
Quel facteur a augmenté de 10x entre 2000 et 2006 concernant le stockage ?

- A) Le nombre d'utilisateurs
- B) La capacité des disques
- C) La vitesse des réseaux
- D) Le nombre de serveurs

---

### Question 17
Apache Zookeeper est utilisé pour :

- A) Le stockage de fichiers distribués
- B) La coordination et gestion de configuration des systèmes distribués
- C) Le traitement de données en temps réel
- D) L'analyse de données

---

### Question 18
Quel pourcentage des données mondiales est structuré ?

- A) 10%
- B) 20%
- C) 40%
- D) 50%

---

### Question 19
Parmi les technologies suivantes, laquelle est un broker de messages ?

- A) Apache HBase
- B) Apache Kafka
- C) Apache Pig
- D) Apache Hive

---

### Question 20
En quelle année Google a-t-il publié le papier sur Google File System (GFS) ?

- A) 2001
- B) 2003
- C) 2005
- D) 2007

---

### Question 21
Quelle est la définition correcte du "Stream Processing" ?

- A) Traitement de données historiques stockées
- B) Traitement de flux de données en temps réel de façon continue
- C) Traitement uniquement des données structurées
- D) Compression des données avant stockage

---

### Question 22
Quelle technologie utilise le langage Pig Latin ?

- A) Apache Hive
- B) Apache Pig
- C) Apache Spark
- D) Apache Storm

---

### Question 23
Combien de tweets sont publiés par jour sur Twitter (approximativement) ?

- A) 50 millions
- B) 200 millions
- C) 504 millions
- D) 1 milliard

---

### Question 24
Apache Flume est utilisé pour :

- A) Le traitement MapReduce
- B) La collecte et l'analyse de fichiers logs
- C) Le stockage NoSQL
- D) La visualisation de données

---

### Question 25
Quelle est la caractéristique principale de Cassandra ?

- A) Traitement en temps réel uniquement
- B) Base de données NoSQL à haute disponibilité sans point de défaillance unique
- C) Stockage de fichiers uniquement
- D) Langage SQL standard

---

### Question 26
Le "Native Streaming" se caractérise par :

- A) Le traitement par mini-lots
- B) Le traitement de chaque enregistrement dès son arrivée sans attendre les autres
- C) Le stockage des données avant traitement
- D) L'utilisation uniquement de Spark

---

### Question 27
Quelle unité de stockage équivaut à 1,024 Zettaoctets ?

- A) Exaoctet
- B) Pétaoctet
- C) Yottaoctet
- D) Téraoctet

---

### Question 28
Parmi les frameworks suivants, lequel utilise l'approche Micro-batch ?

- A) Apache Storm
- B) Apache Flink
- C) Spark Streaming
- D) Kafka Streams

---

### Question 29
Que représente la "Valeur" dans le modèle des 5V du Big Data ?

- A) Le coût du stockage
- B) Le profit et les connaissances extraites des données
- C) La vitesse de traitement
- D) Le volume des données

---

### Question 30
Apache Oozie est utilisé pour :

- A) Le stockage de données
- B) L'ordonnancement de workflows Hadoop
- C) Le traitement en temps réel
- D) La messagerie

---

### Question 31
Quelle quantité de données a été produite en 2011 ?

- A) 500 Pétaoctets
- B) 1 Exaoctet
- C) 1.8 Zettaoctets
- D) 5 Yottaoctets

---

### Question 32
ElasticSearch est décrit comme :

- A) Une base de données relationnelle
- B) Un moteur de recherche distribué via interface REST
- C) Un système de fichiers
- D) Un broker de messages

---

### Question 33
Parmi les domaines suivants, lequel N'EST PAS mentionné comme application du Big Data ?

- A) Santé
- B) Commerce de détail
- C) Architecture des bâtiments
- D) Éducation (MOOCs)

---

### Question 34
Quelle technologie est à la fois utilisable pour le batch et le stream processing ?

- A) MapReduce
- B) Apache Storm
- C) Apache Spark
- D) Apache Flume

---

### Question 35
La loi de Moore a été appliquée pendant combien d'années selon le cours ?

- A) 20 ans
- B) 25 ans
- C) 35 ans
- D) 50 ans

---

### Question 36
Quelle est la source principale des données non structurées ?

- A) Bases de données relationnelles
- B) Fichiers Excel
- C) Emails, réseaux sociaux, vidéos, photos
- D) Systèmes ERP

---

### Question 37
Apache Phoenix est construit sur quelle technologie ?

- A) MongoDB
- B) Cassandra
- C) HBase
- D) HDFS

---

### Question 38
Quelle quantité de données représente toute l'information produite jusqu'en 2003 ?

- A) 1 Pétaoctet
- B) 5 Exaoctets
- C) 1 Zettaoctet
- D) 10 Téraoctets

---

### Question 39
Hazelcast est décrit comme :

- A) Un système de fichiers distribués
- B) Un cache mémoire distribué et base de données NoSQL en mémoire
- C) Un framework de machine learning
- D) Un outil de visualisation

---

### Question 40
Pourquoi le Big Data a-t-il émergé ? (Choisir la réponse la plus complète)

- A) Uniquement à cause de l'augmentation du volume de données
- B) L'augmentation exponentielle des données non structurées, l'augmentation des capacités de stockage/analyse, et l'inadéquation des technologies existantes
- C) La baisse des prix des ordinateurs
- D) L'invention d'Internet

---

## Fin du QCM

**Instructions:** Pour chaque question, sélectionnez la meilleure réponse parmi les options proposées (A, B, C ou D).
